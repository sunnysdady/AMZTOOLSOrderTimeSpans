import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta  # å¤„ç†æœˆä»½è®¡ç®—

# --------------------------
# é¡µé¢åŸºç¡€é…ç½®
# --------------------------
st.set_page_config(
    page_title="è®¢å•å‡ºå•æ—¶é—´ç»Ÿè®¡çœ‹æ¿",
    page_icon="ğŸ“Š",
    layout="wide"  # å®½å±å¸ƒå±€ï¼Œé€‚é…çœ‹æ¿å±•ç¤º
)

# --------------------------
# å…¨å±€å¸¸é‡å®šä¹‰ï¼ˆæ–°å¢ï¼šè§£å†³week_orderæœªå®šä¹‰é—®é¢˜ï¼‰
# --------------------------
WEEK_ORDER = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']  # å…¨å±€æ˜ŸæœŸæ’åº

# --------------------------
# è¾…åŠ©å‡½æ•°ï¼šæ•°æ®å¤„ç†
# --------------------------
def process_order_data(df, time_column):
    """
    å¤„ç†è®¢å•æ•°æ®ï¼Œæå–å°æ—¶ã€æ˜ŸæœŸç»´åº¦
    :param df: åŸå§‹è®¢å•DataFrame
    :param time_column: è®¢å•æ—¶é—´å­—æ®µå
    :return: å¤„ç†åçš„DataFrame
    """
    # è½¬æ¢æ—¶é—´å­—æ®µä¸ºdatetimeæ ¼å¼
    df[time_column] = pd.to_datetime(df[time_column], errors='coerce')
    
    # è¿‡æ»¤æ— æ•ˆæ—¶é—´æ•°æ®
    df = df.dropna(subset=[time_column])
    
    # æå–ç»´åº¦å­—æ®µ
    df['å°æ—¶'] = df[time_column].dt.hour  # 0-23å°æ—¶
    df['æ˜ŸæœŸ'] = df[time_column].dt.dayofweek  # 0=å‘¨ä¸€ï¼Œ6=å‘¨æ—¥
    # æ˜ å°„æ˜ŸæœŸæ•°å­—ä¸ºä¸­æ–‡
    week_mapping = {0: 'å‘¨ä¸€', 1: 'å‘¨äºŒ', 2: 'å‘¨ä¸‰', 3: 'å‘¨å››', 4: 'å‘¨äº”', 5: 'å‘¨å…­', 6: 'å‘¨æ—¥'}
    df['æ˜ŸæœŸ'] = df['æ˜ŸæœŸ'].map(week_mapping)
    
    return df

def get_hourly_stats(df):
    """æŒ‰å°æ—¶ç»Ÿè®¡è®¢å•æ•°"""
    hourly_stats = df.groupby('å°æ—¶').size().reset_index(name='è®¢å•æ•°')
    # è¡¥å…¨0-23å°æ—¶ï¼ˆé¿å…æŸäº›å°æ—¶æ— æ•°æ®æ—¶å›¾è¡¨æ–­å±‚ï¼‰
    all_hours = pd.DataFrame({'å°æ—¶': range(24)})
    hourly_stats = pd.merge(all_hours, hourly_stats, on='å°æ—¶', how='left').fillna(0)
    return hourly_stats

def get_weekly_stats(df):
    """æŒ‰æ˜ŸæœŸç»Ÿè®¡è®¢å•æ•°"""
    weekly_stats = df.groupby('æ˜ŸæœŸ').size().reset_index(name='è®¢å•æ•°')
    # å¼ºåˆ¶æŒ‰å‘¨ä¸€åˆ°å‘¨æ—¥æ’åºï¼ˆä½¿ç”¨å…¨å±€å¸¸é‡ï¼‰
    weekly_stats['æ˜ŸæœŸ'] = pd.Categorical(weekly_stats['æ˜ŸæœŸ'], categories=WEEK_ORDER, ordered=True)
    weekly_stats = weekly_stats.sort_values('æ˜ŸæœŸ').reset_index(drop=True)
    return weekly_stats

def get_week_hour_cross_stats(df):
    """æ˜ŸæœŸÃ—å°æ—¶äº¤å‰ç»Ÿè®¡ï¼ˆæ ¸å¿ƒçœ‹æ¿ï¼‰"""
    cross_stats = df.groupby(['æ˜ŸæœŸ', 'å°æ—¶']).size().reset_index(name='è®¢å•æ•°')
    # è¡¥å…¨æ‰€æœ‰æ˜ŸæœŸÃ—å°æ—¶ç»„åˆï¼ˆä½¿ç”¨å…¨å±€å¸¸é‡ï¼‰
    all_week_hour = pd.MultiIndex.from_product([WEEK_ORDER, range(24)], names=['æ˜ŸæœŸ', 'å°æ—¶']).to_frame(index=False)
    cross_stats = pd.merge(all_week_hour, cross_stats, on=['æ˜ŸæœŸ', 'å°æ—¶'], how='left').fillna(0)
    return cross_stats

def calculate_time_range(data_max_date, range_type):
    """
    æ ¹æ®é€‰æ‹©çš„æ—¶é—´èŒƒå›´ç±»å‹ï¼Œè®¡ç®—èµ·å§‹æ—¥æœŸ
    :param data_max_date: è®¢å•æ•°æ®ä¸­çš„æœ€å¤§æ—¥æœŸï¼ˆæœ€æ–°è®¢å•æ—¥æœŸï¼‰
    :param range_type: æ—¶é—´èŒƒå›´ç±»å‹ï¼ˆè¿‘7å¤©/14å¤©/30å¤©/ä¸Šä¸ªæœˆ/è‡ªå®šä¹‰ï¼‰
    :return: èµ·å§‹æ—¥æœŸï¼ˆdatetimeå¯¹è±¡ï¼‰
    """
    if range_type == "è¿‘7å¤©":
        start_date = data_max_date - timedelta(days=7)
    elif range_type == "è¿‘14å¤©":
        start_date = data_max_date - timedelta(days=14)
    elif range_type == "è¿‘30å¤©":
        start_date = data_max_date - timedelta(days=30)
    elif range_type == "ä¸Šä¸ªæœˆ":
        # ä¸Šä¸ªæœˆç¬¬ä¸€å¤© åˆ° ä¸Šä¸ªæœˆæœ€åä¸€å¤©
        last_month = data_max_date - relativedelta(months=1)
        start_date = datetime(last_month.year, last_month.month, 1)
    else:  # è‡ªå®šä¹‰ï¼Œåç»­ç”±ç”¨æˆ·é€‰æ‹©çš„æ—¥æœŸå†³å®š
        start_date = None
    return start_date

# --------------------------
# é¡µé¢UI & æ ¸å¿ƒé€»è¾‘
# --------------------------
st.title("ğŸ“Š è®¢å•å‡ºå•æ—¶é—´ç»Ÿè®¡çœ‹æ¿")
st.divider()

# 1. æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
st.subheader("1. ä¸Šä¼ è®¢å•æ–‡ä»¶")
uploaded_file = st.file_uploader(
    "æ”¯æŒæ ¼å¼ï¼šExcel(.xlsx)ã€CSV(.csv)",
    type=['xlsx', 'csv'],
    help="è¯·ç¡®ä¿æ–‡ä»¶åŒ…å«è®¢å•æ—¶é—´å­—æ®µï¼ˆå¦‚ï¼šå‡ºå•æ—¶é—´ã€ä¸‹å•æ—¶é—´ç­‰ï¼‰"
)

if uploaded_file is not None:
    # è¯»å–æ–‡ä»¶
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        
        # å±•ç¤ºåŸå§‹æ•°æ®é¢„è§ˆ
        st.subheader("æ•°æ®é¢„è§ˆ")
        st.dataframe(df.head(5), use_container_width=True)
        
        # è®©ç”¨æˆ·é€‰æ‹©è®¢å•æ—¶é—´å­—æ®µ
        time_column = st.selectbox(
            "è¯·é€‰æ‹©è®¢å•æ—¶é—´å­—æ®µ",
            options=df.columns.tolist(),
            help="é€‰æ‹©åŒ…å«å‡ºå•æ—¶é—´çš„åˆ—ï¼ˆå¦‚ï¼šä¸‹å•æ—¶é—´ã€æ”¯ä»˜æ—¶é—´ç­‰ï¼‰"
        )
        
        # å¤„ç†æ•°æ®
        with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
            processed_df = process_order_data(df, time_column)
        
        st.success("æ•°æ®å¤„ç†å®Œæˆï¼")
        st.divider()
        
        # 2. æ—¶é—´èŒƒå›´ç­›é€‰åŒºåŸŸ
        st.subheader("2. æ—¶é—´èŒƒå›´ç­›é€‰")
        
        # è·å–è®¢å•æ•°æ®çš„æ—¶é—´è¾¹ç•Œ
        data_min_date = processed_df[time_column].dt.date.min()
        data_max_date = processed_df[time_column].dt.date.max()
        data_max_datetime = processed_df[time_column].max()  # å¸¦æ—¶åˆ†ç§’çš„æœ€æ–°æ—¶é—´
        
        # æ˜¾ç¤ºæ•°æ®æ—¶é—´èŒƒå›´æç¤º
        st.info(f"å½“å‰è®¢å•æ•°æ®æ—¶é—´èŒƒå›´ï¼š{data_min_date} ~ {data_max_date}")
        
        # å¿«æ·æ—¶é—´èŒƒå›´æŒ‰é’®ï¼ˆä¸€è¡Œæ’åˆ—ï¼‰
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            btn_7d = st.button("è¿‘7å¤©", use_container_width=True)
        with col2:
            btn_14d = st.button("è¿‘14å¤©", use_container_width=True)
        with col3:
            btn_30d = st.button("è¿‘30å¤©", use_container_width=True)
        with col4:
            btn_last_month = st.button("ä¸Šä¸ªæœˆ", use_container_width=True)
        with col5:
            btn_all = st.button("å…¨éƒ¨æ•°æ®", use_container_width=True)
        
        # è‡ªå®šä¹‰æ—¥æœŸé€‰æ‹©å™¨
        st.markdown("##### æˆ–è‡ªå®šä¹‰æ—¶é—´èŒƒå›´")
        col_start, col_end = st.columns(2)
        with col_start:
            custom_start_date = st.date_input(
                "å¼€å§‹æ—¥æœŸ",
                value=data_min_date,
                min_value=data_min_date,
                max_value=data_max_date
            )
        with col_end:
            custom_end_date = st.date_input(
                "ç»“æŸæ—¥æœŸ",
                value=data_max_date,
                min_value=data_min_date,
                max_value=data_max_date
            )
        
        # ç¡®å®šæœ€ç»ˆç­›é€‰çš„æ—¶é—´èŒƒå›´
        filter_start_date = None
        filter_end_date = data_max_date  # é»˜è®¤ç»“æŸæ—¥æœŸä¸ºæœ€æ–°
        
        if btn_7d:
            filter_start_date = (data_max_datetime - timedelta(days=7)).date()
        elif btn_14d:
            filter_start_date = (data_max_datetime - timedelta(days=14)).date()
        elif btn_30d:
            filter_start_date = (data_max_datetime - timedelta(days=30)).date()
        elif btn_last_month:
            # ä¸Šä¸ªæœˆçš„æ—¶é—´èŒƒå›´ï¼šä¸Šä¸ªæœˆ1å· åˆ° ä¸Šä¸ªæœˆæœ€åä¸€å¤©
            last_month = data_max_datetime - relativedelta(months=1)
            filter_start_date = datetime(last_month.year, last_month.month, 1).date()
            # è®¡ç®—ä¸Šä¸ªæœˆæœ€åä¸€å¤©
            first_day_current_month = datetime(data_max_datetime.year, data_max_datetime.month, 1)
            filter_end_date = (first_day_current_month - timedelta(days=1)).date()
        elif btn_all:
            filter_start_date = data_min_date
        else:
            # è‡ªå®šä¹‰æ—¥æœŸ
            filter_start_date = custom_start_date
            filter_end_date = custom_end_date
        
        # è¿‡æ»¤æ•°æ®ï¼ˆè½¬æ¢ä¸ºdateæ¯”è¾ƒï¼Œé¿å…æ—¶åˆ†ç§’å¹²æ‰°ï¼‰
        processed_df['è®¢å•æ—¥æœŸ'] = processed_df[time_column].dt.date
        filtered_df = processed_df[
            (processed_df['è®¢å•æ—¥æœŸ'] >= filter_start_date) & 
            (processed_df['è®¢å•æ—¥æœŸ'] <= filter_end_date)
        ]
        
        # éªŒè¯è¿‡æ»¤åçš„æ•°æ®æ˜¯å¦ä¸ºç©º
        if len(filtered_df) == 0:
            st.warning(f"æ‰€é€‰æ—¶é—´èŒƒå›´ï¼ˆ{filter_start_date} ~ {filter_end_date}ï¼‰å†…æ— è®¢å•æ•°æ®ï¼")
        else:
            st.success(f"ç­›é€‰å‡º {filter_start_date} ~ {filter_end_date} çš„è®¢å•æ•°æ®ï¼Œå…± {len(filtered_df)} æ¡")
            
            # é‡æ–°ç»Ÿè®¡ç­›é€‰åçš„æ•°æ®
            hourly_stats = get_hourly_stats(filtered_df)
            weekly_stats = get_weekly_stats(filtered_df)
            cross_stats = get_week_hour_cross_stats(filtered_df)
            
            # 3. æ•°æ®çœ‹æ¿åŒºåŸŸ
            st.divider()
            st.subheader("3. æ•°æ®çœ‹æ¿")
            
            # åˆ†æ å±•ç¤ºï¼šå·¦ä¾§æ˜ŸæœŸç»´åº¦ï¼Œå³ä¾§å°æ—¶ç»´åº¦
            col_week, col_hour = st.columns(2)
            
            # 3.1 æ˜ŸæœŸç»´åº¦ç»Ÿè®¡
            with col_week:
                st.markdown("#### æŒ‰æ˜ŸæœŸç»Ÿè®¡")
                # å¯è§†åŒ–ï¼šæŸ±çŠ¶å›¾
                fig_week = px.bar(
                    weekly_stats,
                    x='æ˜ŸæœŸ',
                    y='è®¢å•æ•°',
                    title=f'å„æ˜ŸæœŸè®¢å•æ•°é‡ï¼ˆ{filter_start_date} ~ {filter_end_date}ï¼‰',
                    color='è®¢å•æ•°',
                    color_continuous_scale='Blues',
                    height=400
                )
                fig_week.update_layout(showlegend=False)
                st.plotly_chart(fig_week, use_container_width=True)
                # æ•°æ®è¡¨æ ¼
                with st.expander("æŸ¥çœ‹æ˜ŸæœŸç»Ÿè®¡æ•°æ®"):
                    st.dataframe(weekly_stats, use_container_width=True)
            
            # 3.2 å°æ—¶ç»´åº¦ç»Ÿè®¡
            with col_hour:
                st.markdown("#### æŒ‰24å°æ—¶ç»Ÿè®¡")
                # å¯è§†åŒ–ï¼šæŠ˜çº¿å›¾ï¼ˆæ›´é€‚åˆå°æ—¶è¶‹åŠ¿ï¼‰
                fig_hour = px.line(
                    hourly_stats,
                    x='å°æ—¶',
                    y='è®¢å•æ•°',
                    title=f'24å°æ—¶è®¢å•æ•°é‡è¶‹åŠ¿ï¼ˆ{filter_start_date} ~ {filter_end_date}ï¼‰',
                    markers=True,
                    height=400
                )
                fig_hour.update_xaxes(tick0=0, dtick=1)  # å°æ—¶è½´æ˜¾ç¤º0-23
                st.plotly_chart(fig_hour, use_container_width=True)
                # æ•°æ®è¡¨æ ¼
                with st.expander("æŸ¥çœ‹å°æ—¶ç»Ÿè®¡æ•°æ®"):
                    st.dataframe(hourly_stats, use_container_width=True)
            
            # 3.3 æ˜ŸæœŸÃ—24å°æ—¶äº¤å‰åˆ†æï¼ˆçƒ­åŠ›å›¾ï¼‰- ä¿®å¤week_orderæœªå®šä¹‰é—®é¢˜
            st.markdown("#### æ˜ŸæœŸÃ—24å°æ—¶äº¤å‰åˆ†æï¼ˆçƒ­åŠ›å›¾ï¼‰")
            # è½¬æ¢ä¸ºé€è§†è¡¨é€‚é…çƒ­åŠ›å›¾ï¼ˆä½¿ç”¨å…¨å±€å¸¸é‡WEEK_ORDERï¼‰
            pivot_table = cross_stats.pivot(index='æ˜ŸæœŸ', columns='å°æ—¶', values='è®¢å•æ•°')
            # æŒ‰å‘¨ä¸€åˆ°å‘¨æ—¥æ’åºï¼ˆä½¿ç”¨å…¨å±€å¸¸é‡ï¼‰
            pivot_table = pivot_table.reindex(WEEK_ORDER)
            
            fig_heatmap = go.Figure(data=go.Heatmap(
                z=pivot_table.values,
                x=pivot_table.columns,
                y=pivot_table.index,
                colorscale='YlGnBu',
                hoverongaps=False,
                hovertemplate='æ˜ŸæœŸï¼š%{y}<br>å°æ—¶ï¼š%{x}<br>è®¢å•æ•°ï¼š%{z}<extra></extra>'
            ))
            fig_heatmap.update_layout(
                title=f'å„æ—¶æ®µè®¢å•åˆ†å¸ƒçƒ­åŠ›å›¾ï¼ˆ{filter_start_date} ~ {filter_end_date}ï¼‰',
                xaxis_title='å°æ—¶',
                yaxis_title='æ˜ŸæœŸ',
                height=500
            )
            st.plotly_chart(fig_heatmap, use_container_width=True)
            
            # 4. æ•°æ®ä¸‹è½½åŒºåŸŸ
            st.divider()
            st.subheader("4. æ•°æ®ä¸‹è½½")
            col_download1, col_download2 = st.columns(2)
            with col_download1:
                # å¯¼å‡ºå°æ—¶ç»Ÿè®¡æ•°æ®
                csv_hour = hourly_stats.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ä¸‹è½½24å°æ—¶ç»Ÿè®¡æ•°æ®",
                    data=csv_hour,
                    file_name=f"è®¢å•å°æ—¶ç»Ÿè®¡_{filter_start_date}_{filter_end_date}.csv",
                    mime="text/csv"
                )
            with col_download2:
                # å¯¼å‡ºæ˜ŸæœŸç»Ÿè®¡æ•°æ®
                csv_week = weekly_stats.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ä¸‹è½½æ˜ŸæœŸç»Ÿè®¡æ•°æ®",
                    data=csv_week,
                    file_name=f"è®¢å•æ˜ŸæœŸç»Ÿè®¡_{filter_start_date}_{filter_end_date}.csv",
                    mime="text/csv"
                )
    
    except Exception as e:
        st.error(f"æ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")
        st.info("è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æ—¶é—´å­—æ®µæ˜¯å¦åŒ…å«æœ‰æ•ˆæ—¶é—´æ•°æ®")
else:
    st.info("è¯·ä¸Šä¼ è®¢å•æ–‡ä»¶å¼€å§‹åˆ†æï¼ˆæ”¯æŒExcel/CSVæ ¼å¼ï¼‰")
