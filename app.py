import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta

# --------------------------
# é¡µé¢åŸºç¡€é…ç½®
# --------------------------
st.set_page_config(
    page_title="è·¨å¢ƒç”µå•†æ•°æ®åˆ†æå·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide"
)

# --------------------------
# å…¨å±€å¸¸é‡
# --------------------------
WEEK_ORDER = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']

# --------------------------
# è¾…åŠ©å‡½æ•°ï¼šæ•°æ®å¤„ç†
# --------------------------
def process_order_data(df, time_column):
    df[time_column] = pd.to_datetime(df[time_column], errors='coerce')
    df = df.dropna(subset=[time_column])
    df['å°æ—¶'] = df[time_column].dt.hour
    df['æ˜ŸæœŸ'] = df[time_column].dt.dayofweek
    week_mapping = {0: 'å‘¨ä¸€', 1: 'å‘¨äºŒ', 2: 'å‘¨ä¸‰', 3: 'å‘¨å››', 4: 'å‘¨äº”', 5: 'å‘¨å…­', 6: 'å‘¨æ—¥'}
    df['æ˜ŸæœŸ'] = df['æ˜ŸæœŸ'].map(week_mapping)
    df['è®¢å•æ—¥æœŸ'] = df[time_column].dt.date
    return df

def get_hourly_stats(df):
    hourly_stats = df.groupby('å°æ—¶').size().reset_index(name='è®¢å•æ•°')
    all_hours = pd.DataFrame({'å°æ—¶': range(24)})
    hourly_stats = pd.merge(all_hours, hourly_stats, on='å°æ—¶', how='left').fillna(0)
    return hourly_stats

def get_weekly_stats(df):
    weekly_stats = df.groupby('æ˜ŸæœŸ').size().reset_index(name='è®¢å•æ•°')
    weekly_stats['æ˜ŸæœŸ'] = pd.Categorical(weekly_stats['æ˜ŸæœŸ'], categories=WEEK_ORDER, ordered=True)
    weekly_stats = weekly_stats.sort_values('æ˜ŸæœŸ').reset_index(drop=True)
    return weekly_stats

def get_week_hour_cross_stats(df):
    cross_stats = df.groupby(['æ˜ŸæœŸ', 'å°æ—¶']).size().reset_index(name='è®¢å•æ•°')
    all_week_hour = pd.MultiIndex.from_product([WEEK_ORDER, range(24)], names=['æ˜ŸæœŸ', 'å°æ—¶']).to_frame(index=False)
    cross_stats = pd.merge(all_week_hour, cross_stats, on=['æ˜ŸæœŸ', 'å°æ—¶'], how='left').fillna(0)
    return cross_stats

def get_sku_ranking(df):
    required_cols = ['SKU', 'æ•°é‡', 'é‡‡è´­æ€»é¢', 'é”€å”®æ€»é¢']
    for col in required_cols:
        if col not in df.columns:
            st.error(f"æ•°æ®ä¸­ç¼ºå°‘å¿…è¦å­—æ®µï¼š{col}ï¼Œæ— æ³•ç”ŸæˆSKUæ’è¡Œæ¦œ")
            return pd.DataFrame()
    sku_stats = df.groupby('SKU').agg(
        é”€é‡=('æ•°é‡', 'sum'),
        è®¢å•é‡=('è®¢å•å·', 'nunique'),
        é‡‡è´­æ€»é¢=('é‡‡è´­æ€»é¢', 'sum'),
        é”€å”®é¢=('é”€å”®æ€»é¢', 'sum')
    ).reset_index()
    sku_stats['å‡€é”€å”®é¢'] = sku_stats['é”€å”®é¢'] - sku_stats['é‡‡è´­æ€»é¢']
    sku_stats['å¹³å‡ä»·æ ¼'] = sku_stats['é”€å”®é¢'] / sku_stats['é”€é‡']
    sku_stats[['é‡‡è´­æ€»é¢', 'é”€å”®é¢', 'å‡€é”€å”®é¢', 'å¹³å‡ä»·æ ¼']] = sku_stats[['é‡‡è´­æ€»é¢', 'é”€å”®é¢', 'å‡€é”€å”®é¢', 'å¹³å‡ä»·æ ¼']].round(2)
    sku_stats = sku_stats.sort_values('é”€é‡', ascending=False).reset_index(drop=True)
    sku_stats.insert(0, 'åºå·', range(1, len(sku_stats)+1))
    return sku_stats

# --------------------------
# é”€é‡åˆ†æçœ‹æ¿æ ¸å¿ƒå‡½æ•°
# --------------------------
def get_sales_metrics(df, today_date, yesterday_date, last_week_today_date):
    today_data = df[df['è®¢å•æ—¥æœŸ'] == today_date]
    yesterday_data = df[df['è®¢å•æ—¥æœŸ'] == yesterday_date]
    last_week_today_data = df[df['è®¢å•æ—¥æœŸ'] == last_week_today_date]

    metrics = {
        'today_sales': today_data['æ•°é‡'].sum(),
        'today_revenue': today_data['é”€å”®æ€»é¢'].sum(),
        'today_orders': today_data['è®¢å•å·'].nunique(),
        'today_avg_price': today_data['é”€å”®æ€»é¢'].sum() / today_data['æ•°é‡'].sum() if today_data['æ•°é‡'].sum() > 0 else 0,
        'today_cancel': 0,  # å¯æ ¹æ®å®é™…æ•°æ®è°ƒæ•´
        'yesterday_sales': yesterday_data['æ•°é‡'].sum(),
        'yesterday_revenue': yesterday_data['é”€å”®æ€»é¢'].sum(),
        'yesterday_orders': yesterday_data['è®¢å•å·'].nunique(),
        'yesterday_avg_price': yesterday_data['é”€å”®æ€»é¢'].sum() / yesterday_data['æ•°é‡'].sum() if yesterday_data['æ•°é‡'].sum() > 0 else 0,
        'yesterday_cancel': 0,
        'last_week_today_sales': last_week_today_data['æ•°é‡'].sum(),
        'last_week_today_revenue': last_week_today_data['é”€å”®æ€»é¢'].sum(),
        'last_week_today_orders': last_week_today_data['è®¢å•å·'].nunique(),
        'last_week_today_avg_price': last_week_today_data['é”€å”®æ€»é¢'].sum() / last_week_today_data['æ•°é‡'].sum() if last_week_today_data['æ•°é‡'].sum() > 0 else 0,
        'last_week_today_cancel': 0
    }
    return metrics

def get_hourly_trend(df, today_date, yesterday_date):
    today_hourly = df[df['è®¢å•æ—¥æœŸ'] == today_date].groupby('å°æ—¶')['æ•°é‡'].sum().reset_index(name='ä»Šæ—¥é”€é‡')
    yesterday_hourly = df[df['è®¢å•æ—¥æœŸ'] == yesterday_date].groupby('å°æ—¶')['æ•°é‡'].sum().reset_index(name='æ˜¨æ—¥é”€é‡')
    all_hours = pd.DataFrame({'å°æ—¶': range(24)})
    hourly_trend = pd.merge(all_hours, today_hourly, on='å°æ—¶', how='left').fillna(0)
    hourly_trend = pd.merge(hourly_trend, yesterday_hourly, on='å°æ—¶', how='left').fillna(0)
    return hourly_trend

def get_sku_multi_period(df, today_date, yesterday_date, last_week_today_date):
    today_data = df[df['è®¢å•æ—¥æœŸ'] == today_date]
    yesterday_data = df[df['è®¢å•æ—¥æœŸ'] == yesterday_date]
    last_week_today_data = df[df['è®¢å•æ—¥æœŸ'] == last_week_today_date]
    last_7_days = df[(df['è®¢å•æ—¥æœŸ'] >= today_date - timedelta(days=6)) & (df['è®¢å•æ—¥æœŸ'] <= today_date)]
    last_14_days = df[(df['è®¢å•æ—¥æœŸ'] >= today_date - timedelta(days=13)) & (df['è®¢å•æ—¥æœŸ'] <= today_date)]
    last_30_days = df[(df['è®¢å•æ—¥æœŸ'] >= today_date - timedelta(days=29)) & (df['è®¢å•æ—¥æœŸ'] <= today_date)]

    # ä¿®å¤ï¼šå°†æ•°å­—å¼€å¤´çš„åˆ—åæ”¹ä¸ºçº¯ä¸­æ–‡ï¼ˆä¸ƒå¤©é”€é‡ è€Œé 7å¤©é”€é‡ï¼‰
    sku_today = today_data.groupby('SKU').agg(
        ä»Šæ—¥é”€é‡=('æ•°é‡', 'sum'),
        ä»Šæ—¥è®¢å•é‡=('è®¢å•å·', 'nunique'),
        ä»Šæ—¥é”€å”®é¢=('é”€å”®æ€»é¢', 'sum')
    ).reset_index()
    sku_yesterday = yesterday_data.groupby('SKU').agg(
        æ˜¨æ—¥é”€é‡=('æ•°é‡', 'sum'),
        æ˜¨æ—¥è®¢å•é‡=('è®¢å•å·', 'nunique'),
        æ˜¨æ—¥é”€å”®é¢=('é”€å”®æ€»é¢', 'sum')
    ).reset_index()
    sku_last_week = last_week_today_data.groupby('SKU').agg(
        ä¸Šå‘¨ä»Šæ—¥é”€é‡=('æ•°é‡', 'sum'),
        ä¸Šå‘¨ä»Šæ—¥è®¢å•é‡=('è®¢å•å·', 'nunique'),
        ä¸Šå‘¨ä»Šæ—¥é”€å”®é¢=('é”€å”®æ€»é¢', 'sum')
    ).reset_index()
    sku_7d = last_7_days.groupby('SKU').agg(
        ä¸ƒå¤©é”€é‡=('æ•°é‡', 'sum')  # ä¿®å¤ï¼š7å¤©é”€é‡ â†’ ä¸ƒå¤©é”€é‡
    ).reset_index()
    sku_14d = last_14_days.groupby('SKU').agg(
        åå››å¤©é”€é‡=('æ•°é‡', 'sum')  # ä¿®å¤ï¼š14å¤©é”€é‡ â†’ åå››å¤©é”€é‡
    ).reset_index()
    sku_30d = last_30_days.groupby('SKU').agg(
        ä¸‰åå¤©é”€é‡=('æ•°é‡', 'sum')  # ä¿®å¤ï¼š30å¤©é”€é‡ â†’ ä¸‰åå¤©é”€é‡
    ).reset_index()

    sku_multi = sku_today.merge(sku_yesterday, on='SKU', how='outer')
    sku_multi = sku_multi.merge(sku_last_week, on='SKU', how='outer')
    sku_multi = sku_multi.merge(sku_7d, on='SKU', how='outer')
    sku_multi = sku_multi.merge(sku_14d, on='SKU', how='outer')
    sku_multi = sku_multi.merge(sku_30d, on='SKU', how='outer')
    sku_multi = sku_multi.fillna(0)
    return sku_multi

# --------------------------
# å·¦ä¾§å¯¼èˆªæ 
# --------------------------
with st.sidebar:
    st.title("ğŸ“Š åŠŸèƒ½å¯¼èˆª")
    st.divider()
    selected_page = st.radio(
        "é€‰æ‹©çœ‹æ¿",
        ["é”€é‡åˆ†æçœ‹æ¿", "è®¢å•åˆ†æçœ‹æ¿"],
        index=0
    )

# --------------------------
# ä¸»é¡µé¢é€»è¾‘
# --------------------------
st.title("è·¨å¢ƒç”µå•†æ•°æ®åˆ†æå·¥å…·")
st.divider()

# 1. æ–‡ä»¶ä¸Šä¼ åŒºåŸŸï¼ˆå…¨å±€ï¼‰
st.subheader("1. ä¸Šä¼ è®¢å•æ–‡ä»¶")
uploaded_file = st.file_uploader(
    "æ”¯æŒæ ¼å¼ï¼šExcel(.xlsx)ã€CSV(.csv)",
    type=['xlsx', 'csv'],
    help="è¯·ç¡®ä¿æ–‡ä»¶åŒ…å«è®¢å•æ—¶é—´å­—æ®µï¼ˆå¦‚ï¼šå‡ºå•æ—¶é—´ã€ä¸‹å•æ—¶é—´ç­‰ï¼‰"
)

if uploaded_file is not None:
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)

        st.subheader("æ•°æ®é¢„è§ˆ")
        total_rows = len(df)
        st.success(f"âœ… æˆåŠŸå¯¼å…¥æ•°æ®ï¼Œå…± {total_rows} è¡Œï¼Œä»¥ä¸‹æ˜¯å®Œæ•´æ•°æ®ï¼š")
        st.dataframe(df, use_container_width=True, height=300)

        time_column = st.selectbox(
            "è¯·é€‰æ‹©è®¢å•æ—¶é—´å­—æ®µ",
            options=df.columns.tolist(),
            help="é€‰æ‹©åŒ…å«å‡ºå•æ—¶é—´çš„åˆ—ï¼ˆå¦‚ï¼šä¸‹å•æ—¶é—´ã€æ”¯ä»˜æ—¶é—´ç­‰ï¼‰"
        )

        processed_df = process_order_data(df, time_column)
        st.success("æ•°æ®å¤„ç†å®Œæˆï¼")
        st.divider()

        # --------------------------
        # é”€é‡åˆ†æçœ‹æ¿
        # --------------------------
        if selected_page == "é”€é‡åˆ†æçœ‹æ¿":
            st.subheader("ğŸ“ˆ é”€é‡åˆ†æçœ‹æ¿")
            st.info("å¤åˆ»ä½ æä¾›çš„å›¾ç‰‡æ ·å¼ï¼ŒåŒ…å«æ ¸å¿ƒæŒ‡æ ‡ã€å°æ—¶è¶‹åŠ¿ã€SKUå¤šå‘¨æœŸå¯¹æ¯”")

            # æ—¶é—´å¿«æ·é€‰æ‹©
            st.markdown("#### æ—¶é—´èŒƒå›´é€‰æ‹©")
            col1, col2, col3, col4, col5 = st.columns(5)
            with col1:
                btn_today = st.button("ä»Šæ—¥", use_container_width=True)
            with col2:
                btn_yesterday = st.button("æ˜¨æ—¥", use_container_width=True)
            with col3:
                btn_7d = st.button("è¿‘7å¤©", use_container_width=True)
            with col4:
                btn_14d = st.button("è¿‘14å¤©", use_container_width=True)
            with col5:
                btn_30d = st.button("è¿‘30å¤©", use_container_width=True)

            # è‡ªå®šä¹‰æ—¥æœŸ
            st.markdown("##### æˆ–è‡ªå®šä¹‰æ—¶é—´èŒƒå›´")
            col_start, col_end = st.columns(2)
            data_min_date = processed_df['è®¢å•æ—¥æœŸ'].min()
            data_max_date = processed_df['è®¢å•æ—¥æœŸ'].max()
            with col_start:
                custom_start_date = st.date_input("å¼€å§‹æ—¥æœŸ", value=data_max_date, min_value=data_min_date, max_value=data_max_date)
            with col_end:
                custom_end_date = st.date_input("ç»“æŸæ—¥æœŸ", value=data_max_date, min_value=data_min_date, max_value=data_max_date)

            # ç¡®å®šå½“å‰åˆ†ææ—¥æœŸ
            if btn_today:
                analysis_date = data_max_date
            elif btn_yesterday:
                analysis_date = data_max_date - timedelta(days=1)
            elif btn_7d:
                analysis_date = data_max_date
                start_date = analysis_date - timedelta(days=6)
                end_date = analysis_date
            elif btn_14d:
                analysis_date = data_max_date
                start_date = analysis_date - timedelta(days=13)
                end_date = analysis_date
            elif btn_30d:
                analysis_date = data_max_date
                start_date = analysis_date - timedelta(days=29)
                end_date = analysis_date
            else:
                analysis_date = custom_end_date
                start_date = custom_start_date
                end_date = custom_end_date

            yesterday_date = analysis_date - timedelta(days=1)
            last_week_today_date = analysis_date - timedelta(days=7)

            # æ ¸å¿ƒæŒ‡æ ‡å¡ç‰‡
            st.markdown("#### æ ¸å¿ƒæŒ‡æ ‡")
            metrics = get_sales_metrics(processed_df, analysis_date, yesterday_date, last_week_today_date)
            col1, col2, col3, col4, col5 = st.columns(5)
            with col1:
                st.metric(
                    "é”€é‡",
                    f"{metrics['today_sales']}",
                    delta=f"+{((metrics['today_sales'] - metrics['yesterday_sales']) / metrics['yesterday_sales'] * 100):.2f}%" if metrics['yesterday_sales'] > 0 else "-",
                    delta_color="inverse"
                )
                st.caption(f"æ˜¨æ—¥åŒæ—¶: {metrics['yesterday_sales']} | ä¸Šå‘¨ä»Šæ—¥åŒæ—¶: {metrics['last_week_today_sales']}")
            with col2:
                st.metric(
                    "é”€å”®é¢",
                    f"${metrics['today_revenue']:.2f}",
                    delta=f"+{((metrics['today_revenue'] - metrics['yesterday_revenue']) / metrics['yesterday_revenue'] * 100):.2f}%" if metrics['yesterday_revenue'] > 0 else "-",
                    delta_color="inverse"
                )
                st.caption(f"æ˜¨æ—¥åŒæ—¶: ${metrics['yesterday_revenue']:.2f} | ä¸Šå‘¨ä»Šæ—¥åŒæ—¶: ${metrics['last_week_today_revenue']:.2f}")
            with col3:
                st.metric(
                    "è®¢å•é‡",
                    f"{metrics['today_orders']}",
                    delta=f"+{((metrics['today_orders'] - metrics['yesterday_orders']) / metrics['yesterday_orders'] * 100):.2f}%" if metrics['yesterday_orders'] > 0 else "-",
                    delta_color="inverse"
                )
                st.caption(f"æ˜¨æ—¥åŒæ—¶: {metrics['yesterday_orders']} | ä¸Šå‘¨ä»Šæ—¥åŒæ—¶: {metrics['last_week_today_orders']}")
            with col4:
                st.metric(
                    "é”€å”®å‡ä»·",
                    f"${metrics['today_avg_price']:.2f}",
                    delta=f"{((metrics['today_avg_price'] - metrics['yesterday_avg_price']) / metrics['yesterday_avg_price'] * 100):.2f}%" if metrics['yesterday_avg_price'] > 0 else "-",
                    delta_color="inverse"
                )
                st.caption(f"æ˜¨æ—¥åŒæ—¶: ${metrics['yesterday_avg_price']:.2f} | ä¸Šå‘¨ä»Šæ—¥åŒæ—¶: ${metrics['last_week_today_avg_price']:.2f}")
            with col5:
                st.metric(
                    "å–æ¶ˆè®¢å•æ•°",
                    f"{metrics['today_cancel']}",
                    delta=f"-100.00%" if metrics['last_week_today_cancel'] > 0 else "-",
                    delta_color="inverse"
                )
                st.caption(f"æ˜¨å¤©å…¨å¤©: {metrics['yesterday_cancel']} | ä¸Šå‘¨ä»Šæ—¥å…¨å¤©: {metrics['last_week_today_cancel']}")

            # å°æ—¶è¶‹åŠ¿å›¾
            st.divider()
            st.markdown("#### é”€é‡/é”€å”®é¢å°æ—¶è¶‹åŠ¿")
            hourly_trend = get_hourly_trend(processed_df, analysis_date, yesterday_date)
            col_trend1, col_trend2 = st.columns(2)
            with col_trend1:
                fig_sales_trend = px.line(
                    hourly_trend,
                    x='å°æ—¶',
                    y=['ä»Šæ—¥é”€é‡', 'æ˜¨æ—¥é”€é‡'],
                    title='é”€é‡å°æ—¶è¶‹åŠ¿å¯¹æ¯”',
                    markers=True,
                    height=300
                )
                st.plotly_chart(fig_sales_trend, use_container_width=True)
            with col_trend2:
                today_revenue_hourly = processed_df[processed_df['è®¢å•æ—¥æœŸ'] == analysis_date].groupby('å°æ—¶')['é”€å”®æ€»é¢'].sum().reset_index(name='ä»Šæ—¥é”€å”®é¢')
                yesterday_revenue_hourly = processed_df[processed_df['è®¢å•æ—¥æœŸ'] == yesterday_date].groupby('å°æ—¶')['é”€å”®æ€»é¢'].sum().reset_index(name='æ˜¨æ—¥é”€å”®é¢')
                revenue_trend = pd.merge(pd.DataFrame({'å°æ—¶': range(24)}), today_revenue_hourly, on='å°æ—¶', how='left').fillna(0)
                revenue_trend = pd.merge(revenue_trend, yesterday_revenue_hourly, on='å°æ—¶', how='left').fillna(0)
                fig_revenue_trend = px.line(
                    revenue_trend,
                    x='å°æ—¶',
                    y=['ä»Šæ—¥é”€å”®é¢', 'æ˜¨æ—¥é”€å”®é¢'],
                    title='é”€å”®é¢å°æ—¶è¶‹åŠ¿å¯¹æ¯”',
                    markers=True,
                    height=300
                )
                st.plotly_chart(fig_revenue_trend, use_container_width=True)

            # SKUå¤šå‘¨æœŸå¯¹æ¯”
            st.divider()
            st.markdown("#### SKUå¤šå‘¨æœŸé”€é‡å¯¹æ¯”")
            sku_multi = get_sku_multi_period(processed_df, analysis_date, yesterday_date, last_week_today_date)
            if 'SKU' in processed_df.columns:
                sku_multi = sku_multi.merge(processed_df[['SKU', 'ASIN', 'äº§å“åç§°']].drop_duplicates(), on='SKU', how='left')
                # ä¿®å¤ï¼šåŒæ­¥è°ƒæ•´æ˜¾ç¤ºåˆ—åï¼ˆ7å¤©â†’ä¸ƒå¤©ã€14å¤©â†’åå››å¤©ã€30å¤©â†’ä¸‰åå¤©ï¼‰
                display_cols = ['SKU', 'ASIN', 'äº§å“åç§°', 'ä¸ƒå¤©é”€é‡', 'åå››å¤©é”€é‡', 'ä¸‰åå¤©é”€é‡', 'ä»Šæ—¥é”€é‡', 'ä»Šæ—¥è®¢å•é‡', 'ä»Šæ—¥é”€å”®é¢', 'æ˜¨æ—¥é”€é‡', 'æ˜¨æ—¥è®¢å•é‡', 'æ˜¨æ—¥é”€å”®é¢', 'ä¸Šå‘¨ä»Šæ—¥é”€é‡', 'ä¸Šå‘¨ä»Šæ—¥è®¢å•é‡', 'ä¸Šå‘¨ä»Šæ—¥é”€å”®é¢']
                st.dataframe(sku_multi[display_cols], use_container_width=True, height=400)
            else:
                st.warning("æ•°æ®ä¸­ç¼ºå°‘SKUå­—æ®µï¼Œæ— æ³•ç”ŸæˆSKUå¤šå‘¨æœŸå¯¹æ¯”è¡¨")

        # --------------------------
        # è®¢å•åˆ†æçœ‹æ¿
        # --------------------------
        elif selected_page == "è®¢å•åˆ†æçœ‹æ¿":
            st.subheader("ğŸ“‹ è®¢å•åˆ†æçœ‹æ¿")
            st.info("æ•´åˆæ‰€æœ‰è®¢å•åˆ†æåŠŸèƒ½ï¼šæ—¶é—´èŒƒå›´ç­›é€‰ã€æ˜ŸæœŸ/å°æ—¶ç»Ÿè®¡ã€çƒ­åŠ›å›¾ã€SKUæ’è¡Œæ¦œã€æ•°æ®ä¸‹è½½")

            # æ—¶é—´èŒƒå›´ç­›é€‰
            st.markdown("#### æ—¶é—´èŒƒå›´ç­›é€‰")
            data_min_date = processed_df['è®¢å•æ—¥æœŸ'].min()
            data_max_date = processed_df['è®¢å•æ—¥æœŸ'].max()
            data_max_datetime = processed_df[time_column].max()

            st.info(f"å½“å‰è®¢å•æ•°æ®æ—¶é—´èŒƒå›´ï¼š{data_min_date} ~ {data_max_date}")
            col1, col2, col3, col4, col5 = st.columns(5)
            with col1:
                btn_7d = st.button("è¿‘7å¤©", use_container_width=True, key="order_7d")
            with col2:
                btn_14d = st.button("è¿‘14å¤©", use_container_width=True, key="order_14d")
            with col3:
                btn_30d = st.button("è¿‘30å¤©", use_container_width=True, key="order_30d")
            with col4:
                btn_last_month = st.button("ä¸Šä¸ªæœˆ", use_container_width=True, key="order_last_month")
            with col5:
                btn_all = st.button("å…¨éƒ¨æ•°æ®", use_container_width=True, key="order_all")

            st.markdown("##### æˆ–è‡ªå®šä¹‰æ—¶é—´èŒƒå›´")
            col_start, col_end = st.columns(2)
            with col_start:
                custom_start_date = st.date_input("å¼€å§‹æ—¥æœŸ", value=data_min_date, min_value=data_min_date, max_value=data_max_date, key="order_start")
            with col_end:
                custom_end_date = st.date_input("ç»“æŸæ—¥æœŸ", value=data_max_date, min_value=data_min_date, max_value=data_max_date, key="order_end")

            # ç¡®å®šç­›é€‰èŒƒå›´
            filter_start_date = None
            filter_end_date = data_max_date
            if btn_7d:
                filter_start_date = (data_max_datetime - timedelta(days=7)).date()
            elif btn_14d:
                filter_start_date = (data_max_datetime - timedelta(days=14)).date()
            elif btn_30d:
                filter_start_date = (data_max_datetime - timedelta(days=30)).date()
            elif btn_last_month:
                last_month = data_max_datetime - relativedelta(months=1)
                filter_start_date = datetime(last_month.year, last_month.month, 1).date()
                first_day_current_month = datetime(data_max_datetime.year, data_max_datetime.month, 1)
                filter_end_date = (first_day_current_month - timedelta(days=1)).date()
            elif btn_all:
                filter_start_date = data_min_date
            else:
                filter_start_date = custom_start_date
                filter_end_date = custom_end_date

            filtered_df = processed_df[(processed_df['è®¢å•æ—¥æœŸ'] >= filter_start_date) & (processed_df['è®¢å•æ—¥æœŸ'] <= filter_end_date)]
            if len(filtered_df) == 0:
                st.warning(f"æ‰€é€‰æ—¶é—´èŒƒå›´ï¼ˆ{filter_start_date} ~ {filter_end_date}ï¼‰å†…æ— è®¢å•æ•°æ®ï¼")
            else:
                st.success(f"ç­›é€‰å‡º {filter_start_date} ~ {filter_end_date} çš„è®¢å•æ•°æ®ï¼Œå…± {len(filtered_df)} æ¡")

                # é‡æ–°ç»Ÿè®¡
                hourly_stats = get_hourly_stats(filtered_df)
                weekly_stats = get_weekly_stats(filtered_df)
                cross_stats = get_week_hour_cross_stats(filtered_df)
                sku_ranking = get_sku_ranking(filtered_df)

                # æ•°æ®çœ‹æ¿
                st.divider()
                st.markdown("#### æ•°æ®çœ‹æ¿")
                col_week, col_hour = st.columns(2)
                with col_week:
                    st.markdown("##### æŒ‰æ˜ŸæœŸç»Ÿè®¡")
                    fig_week = px.bar(
                        weekly_stats,
                        x='æ˜ŸæœŸ',
                        y='è®¢å•æ•°',
                        title=f'å„æ˜ŸæœŸè®¢å•æ•°é‡ï¼ˆ{filter_start_date} ~ {filter_end_date}ï¼‰',
                        color='è®¢å•æ•°',
                        color_continuous_scale='Blues',
                        height=350
                    )
                    st.plotly_chart(fig_week, use_container_width=True)
                    with st.expander("æŸ¥çœ‹æ˜ŸæœŸç»Ÿè®¡æ•°æ®"):
                        st.dataframe(weekly_stats, use_container_width=True)
                with col_hour:
                    st.markdown("##### æŒ‰24å°æ—¶ç»Ÿè®¡")
                    fig_hour = px.line(
                        hourly_stats,
                        x='å°æ—¶',
                        y='è®¢å•æ•°',
                        title=f'24å°æ—¶è®¢å•æ•°é‡è¶‹åŠ¿ï¼ˆ{filter_start_date} ~ {filter_end_date}ï¼‰',
                        markers=True,
                        height=350
                    )
                    st.plotly_chart(fig_hour, use_container_width=True)
                    with st.expander("æŸ¥çœ‹å°æ—¶ç»Ÿè®¡æ•°æ®"):
                        st.dataframe(hourly_stats, use_container_width=True)

                # çƒ­åŠ›å›¾
                st.divider()
                st.markdown("#### æ˜ŸæœŸÃ—24å°æ—¶äº¤å‰åˆ†æï¼ˆçƒ­åŠ›å›¾ï¼‰")
                pivot_table = cross_stats.pivot(index='æ˜ŸæœŸ', columns='å°æ—¶', values='è®¢å•æ•°')
                pivot_table = pivot_table.reindex(WEEK_ORDER)
                fig_heatmap = go.Figure(data=go.Heatmap(
                    z=pivot_table.values,
                    x=pivot_table.columns,
                    y=pivot_table.index,
                    colorscale='YlGnBu',
                    hoverongaps=False,
                    hovertemplate='æ˜ŸæœŸï¼š%{y}<br>å°æ—¶ï¼š%{x}<br>è®¢å•æ•°ï¼š%{z}<extra></extra>'
                ))
                fig_heatmap.update_layout(
                    title=f'å„æ—¶æ®µè®¢å•åˆ†å¸ƒçƒ­åŠ›å›¾ï¼ˆ{filter_start_date} ~ {filter_end_date}ï¼‰',
                    xaxis_title='å°æ—¶',
                    yaxis_title='æ˜ŸæœŸ',
                    height=400
                )
                st.plotly_chart(fig_heatmap, use_container_width=True)

                # SKUæ’è¡Œæ¦œ
                st.divider()
                st.markdown("#### SKUé”€é‡æ’è¡Œæ¦œ")
                if not sku_ranking.empty:
                    sort_by = st.selectbox("æŒ‰ä»¥ä¸‹ç»´åº¦æ’åº", options=['é”€é‡', 'é”€å”®é¢'], index=0, key="ranking_sort")
                    top_n = st.slider("æ˜¾ç¤ºå‰Nå", min_value=10, max_value=len(sku_ranking), value=min(50, len(sku_ranking)), step=10, key="ranking_topn")
                    if sort_by == 'é”€é‡':
                        sku_ranking_sorted = sku_ranking.sort_values('é”€é‡', ascending=False).head(top_n)
                    else:
                        sku_ranking_sorted = sku_ranking.sort_values('é”€å”®é¢', ascending=False).head(top_n)
                    st.dataframe(sku_ranking_sorted, use_container_width=True, height=400)
                    csv_sku = sku_ranking_sorted.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label=f"ä¸‹è½½{sort_by}å‰{top_n}åSKUæ•°æ®",
                        data=csv_sku,
                        file_name=f"SKUæ’è¡Œæ¦œ_{sort_by}_å‰{top_n}å_{filter_start_date}_{filter_end_date}.csv",
                        mime="text/csv"
                    )
                else:
                    st.warning("æ— æ³•ç”ŸæˆSKUæ’è¡Œæ¦œï¼Œè¯·æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦åŒ…å«SKUã€æ•°é‡ã€é‡‡è´­æ€»é¢ã€é”€å”®æ€»é¢ç­‰å­—æ®µ")

                # æ•°æ®ä¸‹è½½
                st.divider()
                st.markdown("#### æ•°æ®ä¸‹è½½")
                col_download1, col_download2 = st.columns(2)
                with col_download1:
                    csv_hour = hourly_stats.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ä¸‹è½½24å°æ—¶ç»Ÿè®¡æ•°æ®",
                        data=csv_hour,
                        file_name=f"è®¢å•å°æ—¶ç»Ÿè®¡_{filter_start_date}_{filter_end_date}.csv",
                        mime="text/csv"
                    )
                with col_download2:
                    csv_week = weekly_stats.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ä¸‹è½½æ˜ŸæœŸç»Ÿè®¡æ•°æ®",
                        data=csv_week,
                        file_name=f"è®¢å•æ˜ŸæœŸç»Ÿè®¡_{filter_start_date}_{filter_end_date}.csv",
                        mime="text/csv"
                    )

    except Exception as e:
        st.error(f"æ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")
        st.info("è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æ—¶é—´å­—æ®µæ˜¯å¦åŒ…å«æœ‰æ•ˆæ—¶é—´æ•°æ®")
else:
    st.info("è¯·ä¸Šä¼ è®¢å•æ–‡ä»¶å¼€å§‹åˆ†æï¼ˆæ”¯æŒExcel/CSVæ ¼å¼ï¼‰")
